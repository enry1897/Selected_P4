{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "950ed67e-7557-4a3b-a244-5e44dc891228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "import os\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327c89a6-06c3-409a-9f45-9f99cb35b204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "fn_csv = 'scenes_stereo\\dcase2013_task1_filenamekey.csv'\n",
    "df = pd.read_csv(fn_csv)\n",
    "files = []\n",
    "labels = []\n",
    "files = df['decodedname']\n",
    "labels = df['label']\n",
    "print(len(files))\n",
    "print(len(labels))\n",
    "audio_path = 'scenes_stereo/scenes_stereo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43e27a37-ba07-4ad0-ae64-f5d6df088d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "50\n",
      "150\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "files_train, files_test, labels_train, labels_test = train_test_split(files, labels, test_size=50, random_state=42, shuffle=True)\n",
    "# specificando il random_state ad ogni run ci sarà sempre lo stesso split (riproducibilità)\n",
    "\n",
    "print(len(files_train))  # 150\n",
    "print(len(files_test))   # 50\n",
    "print(len(labels_train))  # 150\n",
    "print(len(labels_test))   # 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b6b60ce1-debd-47b3-8c22-302fdba97d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "augmented_data = []\n",
    "fast_files = []\n",
    "slow_files = []\n",
    "\n",
    "for i, file in enumerate(files_train):\n",
    "    signal, sr = librosa.load(audio_path + file)\n",
    "    label = labels_train.iloc[i]\n",
    "    base_name = os.path.splitext(file)[0]  # es: 'bus12.wav' → 'bus12'\n",
    "\n",
    "    # Aggiungi il segnale originale\n",
    "    augmented_data.append((signal, label, f\"{base_name}_orig.wav\"))\n",
    "\n",
    "    # Crea versioni augmentate\n",
    "    versions = {\n",
    "        'stretch_fast': librosa.effects.time_stretch(signal, rate=1.2),\n",
    "        'stretch_slow': librosa.effects.time_stretch(signal, rate=0.8),\n",
    "        'pitch_up': librosa.effects.pitch_shift(signal, sr=sr, n_steps=2),\n",
    "        'pitch_down': librosa.effects.pitch_shift(signal, sr=sr, n_steps=-2)\n",
    "    }\n",
    "\n",
    "    # Aggiungi i segnali augmentati alla lista\n",
    "    for suffix, aug_signal in versions.items():\n",
    "        filename = f\"{base_name}_{suffix}.wav\"\n",
    "        augmented_data.append((aug_signal, label, filename))\n",
    "        if \"stretch_fast\" in suffix:\n",
    "            fast_files.append(filename)\n",
    "        elif \"stretch_slow\" in suffix:\n",
    "            slow_files.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "90365dd7-4bd3-482c-b06f-38ed17a36140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(fast_files))\n",
    "print(len(slow_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4469332a-858e-4147-a0e0-8aecdf57c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 22050 # solo per assicurarsi che altre funzioni non la cambino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c546bf56-ccd8-483b-8113-482f00e21b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "augmented_path = 'scenes_stereo_augmented/'\n",
    "test_path = 'scenes_stereo_test/'\n",
    "os.makedirs(augmented_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "files_train_aug = []\n",
    "labels_train_aug = []\n",
    "\n",
    "for i, (signal, label, filename) in enumerate(augmented_data):\n",
    "    filepath = os.path.join(augmented_path, filename)\n",
    "    if filename in fast_files:\n",
    "        signal_resampled = librosa.resample(signal, orig_sr=fs, target_sr=int(fs*1.2))\n",
    "        augmented_data[i] = (signal_resampled, label, filename)\n",
    "        sf.write(filepath, signal_resampled, int(fs*1.2))\n",
    "    elif filename in slow_files:\n",
    "        signal_resampled = librosa.resample(signal, orig_sr=fs, target_sr=int(fs*0.8))\n",
    "        augmented_data[i] = (signal_resampled, label, filename)\n",
    "        sf.write(filepath, signal_resampled, int(fs*0.8))\n",
    "    else:\n",
    "        sf.write(filepath, signal, fs)\n",
    "\n",
    "    files_train_aug.append(filename)\n",
    "    labels_train_aug.append(label)\n",
    "\n",
    "# ho resamplato i file stretchati in modo che avessero lo stesso numero di campioni degli altri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c389ce63-f97a-4434-b85d-f3396e9042c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "50\n",
      "750\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(files_train_aug))\n",
    "print(len(files_test))\n",
    "print(len(labels_train_aug))\n",
    "print(len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5620fc5e-9499-4d9e-88c4-618895b795b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "signals_fs = [librosa.load(audio_path + file) for file in files_test]\n",
    "X_test = [s[0] for s in signals_fs]\n",
    "print(len(X_test))\n",
    "y_test = labels_test\n",
    "print(len(y_test))\n",
    "\n",
    "# test è ok, con X_test (segnali) e y_test (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a36c56ff-b2a6-4147-9dfc-ef25278dbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [s for s, l, f in augmented_data]\n",
    "y_train = [l for s, l, f in augmented_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7d509995-da6b-489a-82a0-ee697167cbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "# train è ok, con X_train (segnali) e y_train (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8d05153c-02a5-4ddd-a39b-9eee24fdd59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07f26187-2002-4699-a6cb-73c19ff72cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 661500)\n",
      "(750,)\n",
      "(50, 661500)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# (750, 661500)\n",
    "# (750, )\n",
    "# (50, 661500)\n",
    "# (50, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "59383244-3a1c-45e4-b03b-f4c80b2cc4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 22050 # non fa mai male ridichiararla\n",
    "time_axis = np.arange(len(signals[0]))/fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518db60-04d0-4f3d-bd55-ef9cee296810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "for i in range(50):\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    plt.xlabel('time (s)')\n",
    "    plt.plot(time_axis, X_test[i])\n",
    "    plt.show()\n",
    "    print(y_test[i])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a4f5506-4008-421c-a0ca-b851417022c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 512\n",
    "h = 256\n",
    "n = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "756843a6-0bee-4be3-82cc-4c2861bb1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9bfcebaa-1eb3-4b09-a826-7e2c5769eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(x, fs, n, h):\n",
    "    zcr = librosa.feature.zero_crossing_rate(x, hop_length = h)\n",
    "    mean_zcr = np.mean(zcr)\n",
    "    std_zcr = np.std(zcr)\n",
    "    melspec = librosa.power_to_db(librosa.feature.melspectrogram(y=x, n_fft=n, hop_length=h, n_mels=40))\n",
    "    delta_melspec = librosa.feature.delta(melspec)\n",
    "    delta2_melspec = librosa.feature.delta(delta_melspec)\n",
    "    mean_mel = np.mean(melspec)\n",
    "    std_mel = np.std(melspec)\n",
    "    mean_deltamel = np.mean(delta_melspec)\n",
    "    std_deltamel = np.std(delta_melspec)\n",
    "    mean_delta2mel = np.mean(delta2_melspec)\n",
    "    std_delta2mel = np.std(delta2_melspec)\n",
    "    C = np.abs(librosa.stft(x, n_fft = n, hop_length = h))\n",
    "    S = librosa.amplitude_to_db(C, ref = np.max)\n",
    "    spectral_flux = librosa.onset.onset_strength(S = S, sr = fs)\n",
    "    mfcc = librosa.feature.mfcc(y = x, sr = fs, n_fft = n, hop_length = h)\n",
    "    mean_mfcc = np.mean(mfcc)\n",
    "    std_mfcc = np.std(mfcc)\n",
    "    mean_spectral_flux = np.mean(spectral_flux)\n",
    "    std_spectral_flux = np.std(spectral_flux)\n",
    "    \n",
    "    f_vector = np.concatenate(([mean_zcr, std_zcr], [mean_mel, std_mel], [mean_deltamel, std_deltamel], [mean_delta2mel, std_delta2mel], [mean_spectral_flux, std_spectral_flux], [mean_mfcc, std_mfcc]))\n",
    "    #f_vector = np.concatenate(([mean_zcr, std_zcr], [mean_mel, std_mel], [mean_deltamel, std_deltamel], [mean_delta2mel, std_delta2mel], [mean_spectral_flux, std_spectral_flux]))\n",
    "    return f_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bf4f0de3-2e57-4b7b-ade1-d57eff17f8fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_vector_train = np.zeros((X_train.shape[0], 12))\n",
    "f_vector_test = np.zeros((X_test.shape[0], 12))\n",
    "# se aggiungete/togliete feature dal f_vector ricordatevi di cambiare la dimensione\n",
    "\n",
    "for i in range(0, X_train.shape[0]):\n",
    "    f_vector_train[i, :] = feature_extraction(X_train[i, :], fs = fs, n = n, h = h)\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    f_vector_test[i, :] = feature_extraction(X_test[i, :], fs = fs, n = n, h = h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8403bca6-b7fc-4f19-9ab1-85cfcf68dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "print(f_vector_train.shape)\n",
    "print(f_vector_train[0, :])\n",
    "print(f_vector_train[100, :])\n",
    "plt.plot(f_vector_train[0, :])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ab621b60-9506-451f-b98f-f1271e85fc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.8333333333333334\n",
      "test:  0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mod = SVC(kernel = 'linear', C = 1000)\n",
    "mod.fit(f_vector_train, y_train)\n",
    "train_pred = mod.predict(f_vector_train)\n",
    "accuracy = accuracy_score(y_train, train_pred)\n",
    "print('train: ', accuracy)\n",
    "test_pred = mod.predict(f_vector_test)\n",
    "accuracy = accuracy_score(y_test, test_pred)\n",
    "print('test: ', accuracy)\n",
    "\n",
    "# overfitta!! togliendo mfcc dal feature_vector migliora, però forse il problema è che abbiamo troppi dati di train perché prima con solo 150 andava meglio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0333ea-850d-4f8d-9ab8-e43315fda0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
